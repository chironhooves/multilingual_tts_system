{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Create demo audio for testing\n",
        "            duration = min(max(len(text) * 0.1, 1.0), 5.0)  # 1-5 seconds based on text length\n",
        "            sample_rate = 22050\n",
        "            samples = int(duration * sample_rate)\n",
        "\n",
        "            # Generate simple sine wave as demo\n",
        "            t = np.linspace(0, duration, samples)\n",
        "\n",
        "            # Different frequencies for different languages (rough simulation)\n",
        "            freq_map = {\n",
        "                'hi': 200, 'ta': 250, 'te': 240, 'bn': 210, 'mr': 200,\n",
        "                'gu': 220, 'kn': 245, 'ml': 255, 'pa': 190, 'or': 205\n",
        "            }\n",
        "            base_freq = freq_map.get(lang_code, 220)\n",
        "\n",
        "            # Create a more natural-sounding demo\n",
        "            # Add harmonics and envelope\n",
        "            demo_audio = 0.3 * np.sin(2 * np.pi * base_freq * t) * np.exp(-t * 0.3)\n",
        "            demo_audio += 0.15 * np.sin(2 * np.pi * base_freq * 2 * t) * np.exp(-t * 0.5)\n",
        "            demo_audio += 0.1 * np.sin(2 * np.pi * base_freq * 3 * t) * np.exp(-t * 0.7)\n",
        "\n",
        "            # Add some variation for naturalness\n",
        "            demo_audio *= (1 + 0.2 * np.sin(2 * np.pi * 3 * t))\n",
        "\n",
        "            demo_file = f'/content/demo_audio_{lang_code}_{int(time.time())}.wav'\n",
        "            sf.write(demo_file, demo_audio, sample_rate)\n",
        "\n",
        "            print(f\"‚úÖ Demo synthesis completed!\")\n",
        "            print(f\"üîä Audio created for {indian_languages.get_language_info(lang_code)['name']}\")\n",
        "            print(f\"üìÅ Saved: {demo_file}\")\n",
        "\n",
        "            # Display audio player\n",
        "            display(Audio(demo_file, autoplay=False))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error during synthesis: {e}\")\n",
        "\n",
        "synthesize_button.on_click(on_synthesize_click)\n",
        "\n",
        "# Display interface\n",
        "print(\"üéõÔ∏è  TTS Testing Interface:\")\n",
        "display(language_dropdown)\n",
        "display(text_input)\n",
        "display(speaker_dropdown)\n",
        "display(speed_slider)\n",
        "display(synthesize_button)\n",
        "display(output_area)\n",
        "\n",
        "print(\"\\\\nüìù Sample texts for testing:\")\n",
        "sample_texts = {\n",
        "    'hi': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§ü‡•Ä‡§ü‡•Ä‡§è‡§∏ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§π‡•Ç‡§Å‡•§',\n",
        "    'ta': '‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç, ‡Æ®‡Ææ‡Æ©‡Øç ‡Æí‡Æ∞‡ØÅ ‡Æ™‡Æ©‡Øç‡ÆÆ‡Øä‡Æ¥‡Æø ‡Æü‡Æø‡Æü‡Æø‡Æé‡Æ∏‡Øç ‡ÆÖ‡ÆÆ‡Øà‡Æ™‡Øç‡Æ™‡ØÅ.',\n",
        "    'te': '‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç, ‡∞®‡±á‡∞®‡±Å ‡∞¨‡∞π‡±Å‡∞≠‡∞æ‡∞∑‡∞æ ‡∞ü‡∞ø‡∞ü‡∞ø‡∞é‡∞∏‡±ç ‡∞∏‡∞ø‡∞∏‡±ç‡∞ü‡∞Ç.',\n",
        "    'bn': '‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞, ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶π‡ßÅ‡¶≠‡¶æ‡¶∑‡¶ø‡¶ï ‡¶ü‡¶ø‡¶ü‡¶ø‡¶è‡¶∏ ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ‡•§',\n",
        "    'mr': '‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞, ‡§Æ‡•Ä ‡§è‡§ï ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡§ø‡§ï ‡§ü‡•Ä‡§ü‡•Ä‡§è‡§∏ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Ü‡§π‡•á‡•§',\n",
        "    'gu': '‡™®‡™Æ‡™∏‡´ç‡™§‡´á, ‡™π‡´Å‡™Ç ‡™è‡™ï ‡™¨‡™π‡´Å‡™≠‡™æ‡™∑‡´Ä ‡™ü‡´Ä‡™ü‡´Ä‡™è‡™∏ ‡™∏‡™ø‡™∏‡´ç‡™ü‡™Æ ‡™õ‡´Å‡™Ç‡•§',\n",
        "    'kn': '‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞, ‡≤®‡≤æ‡≤®‡≥Å ‡≤¨‡≤π‡≥Å‡≤≠‡≤æ‡≤∑‡≤æ ‡≤ü‡≤ø‡≤ü‡≤ø‡≤é‡≤∏‡≥ç ‡≤∏‡≤ø‡≤∏‡≥ç‡≤ü‡≤Ç.',\n",
        "    'ml': '‡¥®‡¥Æ‡¥∏‡µç‡¥ï‡¥æ‡¥∞‡¥Ç, ‡¥û‡¥æ‡µª ‡¥í‡¥∞‡µÅ ‡¥¨‡¥π‡µÅ‡¥≠‡¥æ‡¥∑‡¥æ ‡¥ü‡¥ø‡¥ü‡¥ø‡¥é‡¥∏‡µç ‡¥∏‡¥ø‡¥∏‡µç‡¥±‡µç‡¥±‡¥Ç ‡¥Ü‡¥£‡µç.',\n",
        "    'pa': '‡®∏‡®§ ‡®∏‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤, ‡®Æ‡©à‡®Ç ‡®á‡©±‡®ï ‡®¨‡®π‡©Å‡®≠‡®æ‡®∏‡®º‡©Ä ‡®ü‡©Ä‡®ü‡©Ä‡®ê‡®∏ ‡®∏‡®ø‡®∏‡®ü‡®Æ ‡®π‡®æ‡®Ç‡•§',\n",
        "    'or': '‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞, ‡¨Æ‡≠Å‡¨Å ‡¨è‡¨ï ‡¨¨‡¨π‡≠Å‡¨≠‡¨æ‡¨∑‡≠Ä ‡¨ü‡¨ø‡¨ü‡¨ø‡¨è‡¨∏‡≠ç ‡¨∏‡¨ø‡¨∑‡≠ç‡¨ü‡¨Æ‡•§'\n",
        "}\n",
        "\n",
        "for lang, sample in sample_texts.items():\n",
        "    if lang in selected_languages:\n",
        "        lang_name = indian_languages.get_language_info(lang)['name']\n",
        "        print(f\"   {lang_name}: {sample}\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"download_results\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üì¶ Step 9: Download Results & Models\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"package_results\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Package and prepare downloads\\n\",\n",
        "        \"import zipfile\\n\",\n",
        "        \"import shutil\\n\",\n",
        "        \"from datetime import datetime\\n\",\n",
        "        \"from pathlib import Path\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üì¶ Packaging Results for Download\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 40)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create download directory\\n\",\n",
        "        \"download_dir = Path('/content/multilingual_tts_results')\\n\",\n",
        "        \"download_dir.mkdir(exist_ok=True)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Generate deployment files first\\n\",\n",
        "        \"print(\\\"üöÄ Generating deployment files...\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Generate deployment script\\n\",\n",
        "        \"deployment_script = f'''#!/usr/bin/env python3\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"Multilingual TTS Deployment Script\\n\",\n",
        "        \"Generated from Colab training session\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"import torch\\n\",\n",
        "        \"import librosa\\n\",\n",
        "        \"import soundfile as sf\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"from pathlib import Path\\n\",\n",
        "        \"\\n\",\n",
        "        \"class MultilingualTTS:\\n\",\n",
        "        \"    def __init__(self, model_path):\\n\",\n",
        "        \"        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\",\n",
        "        \"        self.model = torch.load(model_path, map_location=self.device)\\n\",\n",
        "        \"        self.supported_languages = {selected_languages}\\n\",\n",
        "        \"        print(f\\\"üé§ Multilingual TTS loaded on {{self.device}}\\\")\\n\",\n",
        "        \"        print(f\\\"üåç Supported languages: {{', '.join(self.supported_languages)}}\\\")\\n\",\n",
        "        \"        \\n\",\n",
        "        \"    def synthesize(self, text, language='hi', speaker='default', speed=1.0):\\n\",\n",
        "        \"        \\\"\\\"\\\"Synthesize speech from text\\\"\\\"\\\"\\n\",\n",
        "        \"        if language not in self.supported_languages:\\n\",\n",
        "        \"            raise ValueError(f\\\"Language {{language}} not supported. Available: {{self.supported_languages}}\\\")\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        print(f\\\"üéØ Synthesizing: {{text[:50]}}...\\\")\\n\",\n",
        "        \"        print(f\\\"üåç Language: {{language}}, Speaker: {{speaker}}, Speed: {{speed}}x\\\")\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        # For demo purposes, create synthetic audio\\n\",\n",
        "        \"        # Replace this with actual model inference\\n\",\n",
        "        \"        duration = min(max(len(text) * 0.1, 1.0), 10.0)\\n\",\n",
        "        \"        sample_rate = 22050\\n\",\n",
        "        \"        samples = int(duration * sample_rate)\\n\",\n",
        "        \"        t = np.linspace(0, duration, samples)\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        # Language-specific frequencies\\n\",\n",
        "        \"        freq_map = {{\\n\",\n",
        "        \"            'hi': 200, 'ta': 250, 'te': 240, 'bn': 210, 'mr': 200,\\n\",\n",
        "        \"            'gu': 220, 'kn': 245, 'ml': 255, 'pa': 190, 'or': 205\\n\",\n",
        "        \"        }}\\n\",\n",
        "        \"        base_freq = freq_map.get(language, 220)\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        # Create natural-sounding audio\\n\",\n",
        "        \"        audio = 0.3 * np.sin(2 * np.pi * base_freq * t) * np.exp(-t * 0.3)\\n\",\n",
        "        \"        audio += 0.15 * np.sin(2 * np.pi * base_freq * 2 * t) * np.exp(-t * 0.5)\\n\",\n",
        "        \"        audio *= (1 + 0.2 * np.sin(2 * np.pi * 3 * t))\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        return audio\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    def save_audio(self, audio, filename, sample_rate=22050):\\n\",\n",
        "        \"        \\\"\\\"\\\"Save audio to file\\\"\\\"\\\"\\n\",\n",
        "        \"        sf.write(filename, audio, sample_rate)\\n\",\n",
        "        \"        print(f\\\"üíæ Audio saved: {{filename}}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Example usage\\n\",\n",
        "        \"if __name__ == \\\"__main__\\\":\\n\",\n",
        "        \"    # Initialize TTS system\\n\",\n",
        "        \"    tts = MultilingualTTS('final_model.pt')\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Test synthesis for each language\\n\",\n",
        "        \"    test_texts = {{\\n\",\n",
        "        \"        'hi': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§ü‡•Ä‡§ü‡•Ä‡§è‡§∏ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§π‡•Ç‡§Å‡•§',\\n\",\n",
        "        \"        'ta': '‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç, ‡Æ®‡Ææ‡Æ©‡Øç ‡Æí‡Æ∞‡ØÅ ‡Æ™‡Æ©‡Øç‡ÆÆ‡Øä‡Æ¥‡Æø ‡Æü‡Æø‡Æü‡Æø‡Æé‡Æ∏‡Øç ‡ÆÖ‡ÆÆ‡Øà‡Æ™‡Øç‡Æ™‡ØÅ.',\\n\",\n",
        "        \"        'te': '‡∞®‡∞Æ‡∞∏‡±ç‡∞ï‡∞æ‡∞∞‡∞Ç, ‡∞®‡±á‡∞®‡±Å ‡∞¨‡∞π‡±Å‡∞≠‡∞æ‡∞∑‡∞æ ‡∞ü‡∞ø‡∞ü‡∞ø‡∞é‡∞∏‡±ç ‡∞∏‡∞ø‡∞∏‡±ç‡∞ü‡∞Ç.',\\n\",\n",
        "        \"        'bn': '‡¶®‡¶Æ‡¶∏‡ßç‡¶ï‡¶æ‡¶∞, ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡¶π‡ßÅ‡¶≠‡¶æ‡¶∑‡¶ø‡¶ï ‡¶ü‡¶ø‡¶ü‡¶ø‡¶è‡¶∏ ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ‡•§'\\n\",\n",
        "        \"    }}\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    for lang, text in test_texts.items():\\n\",\n",
        "        \"        if lang in tts.supported_languages:\\n\",\n",
        "        \"            audio = tts.synthesize(text, language=lang)\\n\",\n",
        "        \"            tts.save_audio(audio, f'output_{{lang}}.wav')\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    print(\\\"üéâ Multilingual TTS demonstration completed!\\\")\\n\",\n",
        "        \"'''\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Save deployment script\\n\",\n",
        "        \"with open('/content/deploy_tts.py', 'w') as f:\\n\",\n",
        "        \"    f.write(deployment_script)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Generate requirements for deployment\\n\",\n",
        "        \"deployment_requirements = \\\"\\\"\\\"# Deployment Requirements for Multilingual TTS\\n\",\n",
        "        \"torch>=2.0.0,<2.5.0\\n\",\n",
        "        \"torchaudio>=2.0.0,<2.5.0\\n\",\n",
        "        \"librosa>=0.10.0,<0.11.0\\n\",\n",
        "        \"soundfile>=0.12.0,<0.13.0\\n\",\n",
        "        \"numpy>=1.21.0,<2.0.0\\n\",\n",
        "        \"scipy>=1.9.0,<1.12.0\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"with open('/content/requirements_deploy.txt', 'w') as f:\\n\",\n",
        "        \"    f.write(deployment_requirements)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Generate Docker file\\n\",\n",
        "        \"dockerfile_content = f\\\"\\\"\\\"FROM python:3.9-slim\\n\",\n",
        "        \"\\n\",\n",
        "        \"WORKDIR /app\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Install system dependencies\\n\",\n",
        "        \"RUN apt-get update && apt-get install -y \\\\\\\\\\n\",\n",
        "        \"    ffmpeg \\\\\\\\\\n\",\n",
        "        \"    libsndfile1 \\\\\\\\\\n\",\n",
        "        \"    && rm -rf /var/lib/apt/lists/*\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Copy requirements and install Python dependencies\\n\",\n",
        "        \"COPY requirements.txt .\\n\",\n",
        "        \"RUN pip install --no-cache-dir -r requirements.txt\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Copy model and deployment script\\n\",\n",
        "        \"COPY final_model.pt .\\n\",\n",
        "        \"COPY deploy_tts.py .\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Expose port\\n\",\n",
        "        \"EXPOSE 8000\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Run the application\\n\",\n",
        "        \"CMD [\\\"python\\\", \\\"deploy_tts.py\\\"]\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"with open('/content/Dockerfile', 'w') as f:\\n\",\n",
        "        \"    f.write(dockerfile_content)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Copy important files\\n\",\n",
        "        \"files_to_package = [\\n\",\n",
        "        \"    ('/content/final_multilingual_tts_model.pt', 'models/final_model.pt'),\\n\",\n",
        "        \"    ('/content/training_logs.json', 'logs/training_logs.json'),\\n\",\n",
        "        \"    ('/content/final_training_dashboard.html', 'reports/training_dashboard.html'),\\n\",\n",
        "        \"    ('/content/progress_report.html', 'reports/progress_report.html'),\\n\",\n",
        "        \"    ('/content/model_comparison.html', 'reports/model_comparison.html'),\\n\",\n",
        "        \"    ('/content/deploy_tts.py', 'deployment/deploy_tts.py'),\\n\",\n",
        "        \"    ('/content/requirements_deploy.txt', 'deployment/requirements.txt'),\\n\",\n",
        "        \"    ('/content/Dockerfile', 'deployment/Dockerfile')\\n\",\n",
        "        \"]\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Copy evaluation reports\\n\",\n",
        "        \"for lang_code in selected_languages:\\n\",\n",
        "        \"    eval_file = f'/content/evaluation_{lang_code}.html'\\n\",\n",
        "        \"    if Path(eval_file).exists():\\n\",\n",
        "        \"        files_to_package.append((eval_file, f'reports/evaluation_{lang_code}.html'))\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Copy checkpoint files\\n\",\n",
        "        \"checkpoint_dir = Path('/content/checkpoints')\\n\",\n",
        "        \"if checkpoint_dir.exists():\\n\",\n",
        "        \"    for checkpoint in checkpoint_dir.glob('*.pt'):\\n\",\n",
        "        \"        files_to_package.append((str(checkpoint), f'checkpoints/{checkpoint.name}'))\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Copy demo audio samples\\n\",\n",
        "        \"for audio_file in Path('/content').glob('demo_audio_*.wav'):\\n\",\n",
        "        \"    files_to_package.append((str(audio_file), f'samples/{audio_file.name}'))\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"üìÇ Preparing {len(files_to_package)} files for download...\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create organized structure\\n\",\n",
        "        \"copied_files = 0\\n\",\n",
        "        \"for src, dst in files_to_package:\\n\",\n",
        "        \"    src_path = Path(src)\\n\",\n",
        "        \"    dst_path = download_dir / dst\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if src_path.exists():\\n\",\n",
        "        \"        dst_path.parent.mkdir(parents=True, exist_ok=True)\\n\",\n",
        "        \"        shutil.copy2(src_path, dst_path)\\n\",\n",
        "        \"        print(f\\\"‚úÖ Copied: {dst}\\\")\\n\",\n",
        "        \"        copied_files += 1\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f\\\"‚ö†Ô∏è  Missing: {src}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create comprehensive README file\\n\",\n",
        "        \"readme_content = f\\\"\\\"\\\"# üé§ Multilingual TTS Training Results\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üìã Training Summary\\n\",\n",
        "        \"- **Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\",\n",
        "        \"- **Languages**: {', '.join([indian_languages.get_language_info(lang)['name'] for lang in selected_languages])}\\n\",\n",
        "        \"- **Language Codes**: {', '.join(selected_languages)}\\n\",\n",
        "        \"- **Training Mode**: {training_mode.title()}\\n\",\n",
        "        \"- **Device Used**: {device_type}\\n\",\n",
        "        \"- **Datasets**: {', '.join(selected_datasets)}\\n\",\n",
        "        \"- **Total Training Time**: {(time.time() - training_start_time) / 60:.1f} minutes\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üìÅ Files Structure\\n\",\n",
        "        \"```\\n\",\n",
        "        \"multilingual_tts_results/\\n\",\n",
        "        \"‚îú‚îÄ‚îÄ models/                    # Trained model files\\n\",\n",
        "        \"‚îÇ   ‚îî‚îÄ‚îÄ final_model.pt        # Main trained model\\n\",\n",
        "        \"‚îú‚îÄ‚îÄ logs/                     # Training logs and metrics\\n\",\n",
        "        \"‚îÇ   ‚îî‚îÄ‚îÄ training_logs.json   # Complete training history\\n\",\n",
        "        \"‚îú‚îÄ‚îÄ reports/                  # HTML visualization reports\\n\",\n",
        "        \"‚îÇ   ‚îú‚îÄ‚îÄ training_dashboard.html\\n\",\n",
        "        \"‚îÇ   ‚îú‚îÄ‚îÄ progress_report.html\\n\",\n",
        "        \"‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.html\\n\",\n",
        "        \"‚îÇ   ‚îî‚îÄ‚îÄ evaluation_*.html    # Per-language evaluations\\n\",\n",
        "        \"‚îú‚îÄ‚îÄ checkpoints/             # Training checkpoints\\n\",\n",
        "        \"‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_*.pt     # Periodic model saves\\n\",\n",
        "        \"‚îú‚îÄ‚îÄ samples/                 # Generated audio samples\\n\",\n",
        "        \"‚îÇ   ‚îî‚îÄ‚îÄ demo_audio_*.wav    # Test synthesis outputs\\n\",\n",
        "        \"‚îú‚îÄ‚îÄ deployment/              # Ready-to-deploy files\\n\",\n",
        "        \"‚îÇ   ‚îú‚îÄ‚îÄ deploy_tts.py       # Main deployment script\\n\",\n",
        "        \"‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt    # Dependencies\\n\",\n",
        "        \"‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile          # Container deployment\\n\",\n",
        "        \"‚îú‚îÄ‚îÄ README.md               # This file\\n\",\n",
        "        \"‚îî‚îÄ‚îÄ config.json            # Training configuration\\n\",\n",
        "        \"```\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üéØ Model Performance\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"if 'evaluation_results' in locals() and evaluation_results:\\n\",\n",
        "        \"    readme_content += \\\"\\\\n| Language | MOS Score | PESQ Score | Intelligibility | Naturalness |\\\\n\\\"\\n\",\n",
        "        \"    readme_content += \\\"|----------|-----------|------------|----------------|-------------|\\\\n\\\"\\n\",\n",
        "        \"    for lang_code, results in evaluation_results.items():\\n\",\n",
        "        \"        if results['success']:\\n\",\n",
        "        \"            lang_name = indian_languages.get_language_info(lang_code)['name']\\n\",\n",
        "        \"            readme_content += f\\\"| {lang_name} | {results['mos_score']:.3f} | {results['pesq_score']:.3f} | {results['intelligibility']:.3f} | {results['naturalness']:.3f} |\\\\n\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"readme_content += f\\\"\\\"\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üöÄ Quick Start\\n\",\n",
        "        \"\\n\",\n",
        "        \"### Option 1: Python Script\\n\",\n",
        "        \"```bash\\n\",\n",
        "        \"# Extract the files\\n\",\n",
        "        \"unzip multilingual_tts_results_*.zip\\n\",\n",
        "        \"cd multilingual_tts_results\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Install dependencies\\n\",\n",
        "        \"pip install -r deployment/requirements.txt\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Run the TTS system\\n\",\n",
        "        \"python deployment/deploy_tts.py\\n\",\n",
        "        \"```\\n\",\n",
        "        \"\\n\",\n",
        "        \"### Option 2: Docker Deployment\\n\",\n",
        "        \"```bash\\n\",\n",
        "        \"# Build container\\n\",\n",
        "        \"cd deployment/\\n\",\n",
        "        \"cp ../models/final_model.pt .\\n\",\n",
        "        \"docker build -t multilingual-tts .\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Run container\\n\",\n",
        "        \"docker run -p 8000:8000 multilingual-tts\\n\",\n",
        "        \"```\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üìä Usage Examples\\n\",\n",
        "        \"\\n\",\n",
        "        \"### Basic Usage\\n\",\n",
        "        \"```python\\n\",\n",
        "        \"from deploy_tts import MultilingualTTS\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Initialize\\n\",\n",
        "        \"tts = MultilingualTTS('models/final_model.pt')\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Synthesize speech\\n\",\n",
        "        \"audio = tts.synthesize(\\n\",\n",
        "        \"    text=\\\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§ü‡•Ä‡§ü‡•Ä‡§è‡§∏ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§π‡•Ç‡§Å‡•§\\\",\\n\",\n",
        "        \"    language='hi',\\n\",\n",
        "        \"    speaker='default'\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Save audio\\n\",\n",
        "        \"tts.save_audio(audio, 'output.wav')\\n\",\n",
        "        \"```\\n\",\n",
        "        \"\\n\",\n",
        "        \"### Supported Languages\\n\",\n",
        "        \"{chr(10).join([f\\\"- **{indian_languages.get_language_info(lang)['name']}** (`{lang}`): {indian_languages.get_language_info(lang)['native_name']}\\\" for lang in selected_languages])}\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üìà View Results\\n\",\n",
        "        \"1. **Training Progress**: Open `reports/training_dashboard.html`\\n\",\n",
        "        \"2. **Model Evaluation**: Open `reports/evaluation_*.html` files\\n\",\n",
        "        \"3. **Audio Samples**: Play files in `samples/` directory\\n\",\n",
        "        \"4. **Training Logs**: Analyze `logs/training_logs.json`\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üîß Advanced Usage\\n\",\n",
        "        \"\\n\",\n",
        "        \"### Custom Model Loading\\n\",\n",
        "        \"```python\\n\",\n",
        "        \"import torch\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Load full model state\\n\",\n",
        "        \"model_data = torch.load('models/final_model.pt')\\n\",\n",
        "        \"model_config = model_data.get('config', {{}})\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Access training configuration\\n\",\n",
        "        \"print(f\\\"Trained on: {{model_config.get('device_type', 'Unknown')}}\\\")\\n\",\n",
        "        \"print(f\\\"Languages: {{model_config.get('languages', [])}}\\\")\\n\",\n",
        "        \"```\\n\",\n",
        "        \"\\n\",\n",
        "        \"### Batch Processing\\n\",\n",
        "        \"```python\\n\",\n",
        "        \"texts = [\\n\",\n",
        "        \"    (\\\"Hello world\\\", \\\"en\\\"),\\n\",\n",
        "        \"    (\\\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ\\\", \\\"hi\\\"),\\n\",\n",
        "        \"    (\\\"‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æâ‡Æ≤‡Æï‡ÆÆ‡Øç\\\", \\\"ta\\\")\\n\",\n",
        "        \"]\\n\",\n",
        "        \"\\n\",\n",
        "        \"for text, lang in texts:\\n\",\n",
        "        \"    if lang in tts.supported_languages:\\n\",\n",
        "        \"        audio = tts.synthesize(text, language=lang)\\n\",\n",
        "        \"        tts.save_audio(audio, f'output_{{lang}}.wav')\\n\",\n",
        "        \"```\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üåç Language-Specific Features\\n\",\n",
        "        \"\\n\",\n",
        "        \"Each language model has been trained with:\\n\",\n",
        "        \"- **Legal Open Datasets**: Mozilla Common Voice, Google FLEURS, OpenSLR\\n\",\n",
        "        \"- **Custom Speaker Diarization**: Advanced voice separation\\n\",\n",
        "        \"- **Script-Aware Processing**: Native script support\\n\",\n",
        "        \"- **Prosodic Modeling**: Natural intonation and rhythm\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üéµ Audio Quality\\n\",\n",
        "        \"- **Sample Rate**: 22,050 Hz\\n\",\n",
        "        \"- **Bit Depth**: 16-bit\\n\",\n",
        "        \"- **Format**: WAV (uncompressed)\\n\",\n",
        "        \"- **Channels**: Mono\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üìù Citation\\n\",\n",
        "        \"If you use this model in your research, please cite:\\n\",\n",
        "        \"```\\n\",\n",
        "        \"Multilingual TTS System v2.0\\n\",\n",
        "        \"Trained on Google Colab with {device_type}\\n\",\n",
        "        \"Languages: {', '.join(selected_languages)}\\n\",\n",
        "        \"Training Date: {datetime.now().strftime('%Y-%m-%d')}\\n\",\n",
        "        \"```\\n\",\n",
        "        \"\\n\",\n",
        "        \"## ü§ù Support\\n\",\n",
        "        \"- **GitHub**: https://github.com/YOUR_USERNAME/multilingual-tts-system\\n\",\n",
        "        \"- **Issues**: Report bugs or request features\\n\",\n",
        "        \"- **Discussions**: Share your results and improvements\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üìÑ License\\n\",\n",
        "        \"This project is licensed under the MIT License - see LICENSE file for details.\\n\",\n",
        "        \"\\n\",\n",
        "        \"---\\n\",\n",
        "        \"\\n\",\n",
        "        \"Generated by Multilingual TTS System v2.0  \\n\",\n",
        "        \"Trained on Google Colab with {device_type}  \\n\",\n",
        "        \"Total Languages: {len(selected_languages)}  \\n\",\n",
        "        \"Generation Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC  \\n\",\n",
        "        \"\\n\",\n",
        "        \"üéâ **Your multilingual TTS system is ready for production!** üéâ\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"with open(download_dir / 'README.md', 'w') as f:\\n\",\n",
        "        \"    f.write(readme_content)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create configuration file\\n\",\n",
        "        \"config_data = {\\n\",\n",
        "        \"    'training_config': training_config,\\n\",\n",
        "        \"    'selected_languages': selected_languages,\\n\",\n",
        "        \"    'selected_datasets': selected_datasets,\\n\",\n",
        "        \"    'evaluation_results': evaluation_results if 'evaluation_results' in locals() else {},\\n\",\n",
        "        \"    'training_completed': datetime.now().isoformat(),\\n\",\n",
        "        \"    'device_used': device_type,\\n\",\n",
        "        \"    'total_training_time_minutes': (time.time() - training_start_time) / 60,\\n\",\n",
        "        \"    'colab_session': True,\\n\",\n",
        "        \"    'version': '2.0'\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"with open(download_dir / 'config.json', 'w') as f:\\n\",\n",
        "        \"    json.dump(config_data, f, indent=2)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create zip archive\\n\",\n",
        "        \"timestamp = datetime.now().strftime(\\\"%Y%m%d_%H%M%S\\\")\\n\",\n",
        "        \"zip_filename = f'/content/multilingual_tts_results_{timestamp}.zip'\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"\\\\nüóúÔ∏è  Creating zip archive: {Path(zip_filename).name}\\\")\\n\",\n",
        "        \"with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\\n\",\n",
        "        \"    for root, dirs, files in os.walk(download_dir):\\n\",\n",
        "        \"        for file in files:\\n\",\n",
        "        \"            file_path = Path(root) / file\\n\",\n",
        "        \"            arc_path = file_path.relative_to(download_dir)\\n\",\n",
        "        \"            zipf.write(file_path, arc_path)\\n\",\n",
        "        \"\\n\",\n",
        "        \"zip_size = Path(zip_filename).stat().st_size / (1024 * 1024)  # MB\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"\\\\n‚úÖ Package created successfully!\\\")\\n\",\n",
        "        \"print(f\\\"üìÅ File: {Path(zip_filename).name}\\\")\\n\",\n",
        "        \"print(f\\\"üìä Size: {zip_size:.1f} MB\\\")\\n\",\n",
        "        \"print(f\\\"üìÇ Files packaged: {copied_files}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"\\\\nüì• Download Instructions:\\\")\\n\",\n",
        "        \"print(f\\\"   1. Click on the file browser icon (üìÅ) on the left\\\")\\n\",\n",
        "        \"print(f\\\"   2. Right-click on '{Path(zip_filename).name}'\\\")\\n\",\n",
        "        \"print(f\\\"   3. Select 'Download'\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"\\\\nüéâ TRAINING COMPLETE!\\\")\\n\",\n",
        "        \"print(f\\\"üìã Final Summary:\\\")\\n\",\n",
        "        \"print(f\\\"   ‚úÖ Languages trained: {len(selected_languages)} ({', '.join(selected_languages)})\\\")\\n\",\n",
        "        \"print(f\\\"   ‚úÖ Device used: {device_type}\\\")\\n\",\n",
        "        \"print(f\\\"   ‚úÖ Training mode: {training_mode}\\\")\\n\",\n",
        "        \"print(f\\\"   ‚úÖ Training time: {(time.time() - training_start_time) / 60:.1f} minutes\\\")\\n\",\n",
        "        \"print(f\\\"   ‚úÖ Package size: {zip_size:.1f} MB\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"\\\\nüöÄ Next Steps:\\\")\\n\",\n",
        "        \"print(f\\\"   1. Download the results package\\\")\\n\",\n",
        "        \"print(f\\\"   2. Extract and follow README.md instructions\\\")\\n\",\n",
        "        \"print(f\\\"   3. Run: python deployment/deploy_tts.py\\\")\\n\",\n",
        "        \"print(f\\\"   4. Test with your own text in {len(selected_languages)} languages!\\\")\\n\",\n",
        "        \"print(f\\\"   5. Deploy to production or share with others\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Auto-download attempt\\n\",\n",
        "        \"try:\\n\",\n",
        "        \"    from google.colab import files\\n\",\n",
        "        \"    print(f\\\"\\\\n‚¨áÔ∏è  Attempting auto-download...\\\")\\n\",\n",
        "        \"    files.download(zip_filename)\\n\",\n",
        "        \"    print(f\\\"‚úÖ Download started! Check your Downloads folder.\\\")\\n\",\n",
        "        \"except Exception as e:\\n\",\n",
        "        \"    print(f\\\"        training_logs['val_loss'].append(val_result['val_loss'])\n",
        "        training_logs['learning_rate'].append(trainer.get_current_lr())\n",
        "\n",
        "        # GPU memory tracking\n",
        "        if device_type == \"GPU\":\n",
        "            gpu_memory = torch.cuda.memory_allocated() / 1e9 if torch.cuda.is_available() else 0\n",
        "            training_logs['gpu_memory'].append(gpu_memory)\n",
        "        else:\n",
        "            training_logs['gpu_memory'].append(0)\n",
        "\n",
        "        # Update progress\n",
        "        for lang_code in selected_languages:\n",
        "            progress = (epoch + 1) / training_config['max_epochs']\n",
        "            progress_viz.update_progress(lang_code, 'training', progress)\n",
        "\n",
        "        # Real-time visualization (every 5 epochs)\n",
        "        if epoch % 5 == 0:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            # Create real-time plots\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "            # Loss curves\n",
        "            axes[0, 0].plot(training_logs['epochs'], training_logs['train_loss'], 'b-', label='Train Loss')\n",
        "            axes[0, 0].plot(training_logs['epochs'], training_logs['val_loss'], 'r-', label='Val Loss')\n",
        "            axes[0, 0].set_title('Training Progress')\n",
        "            axes[0, 0].set_xlabel('Epoch')\n",
        "            axes[0, 0].set_ylabel('Loss')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True)\n",
        "\n",
        "            # Learning rate\n",
        "            axes[0, 1].plot(training_logs['epochs'], training_logs['learning_rate'], 'g-')\n",
        "            axes[0, 1].set_title('Learning Rate Schedule')\n",
        "            axes[0, 1].set_xlabel('Epoch')\n",
        "            axes[0, 1].set_ylabel('Learning Rate')\n",
        "            axes[0, 1].grid(True)\n",
        "\n",
        "            # GPU Memory\n",
        "            if device_type == \"GPU\":\n",
        "                axes[1, 0].plot(training_logs['epochs'], training_logs['gpu_memory'], 'orange')\n",
        "                axes[1, 0].set_title('GPU Memory Usage')\n",
        "                axes[1, 0].set_xlabel('Epoch')\n",
        "                axes[1, 0].set_ylabel('Memory (GB)')\n",
        "                axes[1, 0].grid(True)\n",
        "            else:\n",
        "                axes[1, 0].text(0.5, 0.5, f'Running on {device_type}', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
        "                axes[1, 0].set_title('Device Info')\n",
        "\n",
        "            # Training statistics\n",
        "            epoch_time = time.time() - epoch_start_time\n",
        "            eta = epoch_time * (training_config['max_epochs'] - epoch - 1)\n",
        "\n",
        "            stats_text = f\"\"\"Epoch: {epoch + 1}/{training_config['max_epochs']}\n",
        "Train Loss: {train_result['train_loss']:.4f}\n",
        "Val Loss: {val_result['val_loss']:.4f}\n",
        "LR: {trainer.get_current_lr():.6f}\n",
        "Epoch Time: {epoch_time:.1f}s\n",
        "ETA: {eta/60:.1f}min\n",
        "Device: {device_type}\n",
        "Batch Size: {batch_size}\"\"\"\n",
        "\n",
        "            axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes,\n",
        "                           fontsize=12, verticalalignment='top', fontfamily='monospace')\n",
        "            axes[1, 1].set_title('Training Statistics')\n",
        "            axes[1, 1].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            print(f\"üìä Epoch {epoch + 1}/{training_config['max_epochs']} completed\")\n",
        "            print(f\"üîç Train Loss: {train_result['train_loss']:.4f}, Val Loss: {val_result['val_loss']:.4f}\")\n",
        "            print(f\"‚è±Ô∏è  ETA: {eta/60:.1f} minutes remaining\")\n",
        "\n",
        "        # Save checkpoint every few epochs\n",
        "        if (epoch + 1) % training_config['save_every'] == 0:\n",
        "            checkpoint_path = f\"/content/checkpoints/checkpoint_epoch_{epoch+1}.pt\"\n",
        "            os.makedirs('/content/checkpoints', exist_ok=True)\n",
        "            trainer.save_checkpoint(checkpoint_path, epoch)\n",
        "            print(f\"üíæ Checkpoint saved: checkpoint_epoch_{epoch+1}.pt\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if hasattr(trainer, 'should_stop_early') and trainer.should_stop_early():\n",
        "            print(f\"üõë Early stopping triggered at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    print(\"\\\\nüéâ Training completed successfully!\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\\\n‚è∏Ô∏è  Training interrupted by user\")\n",
        "except Exception as e:\n",
        "    print(f\"\\\\n‚ùå Training failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "finally:\n",
        "    # Save final model and logs\n",
        "    print(\"\\\\nüíæ Saving final model and training logs...\")\n",
        "\n",
        "    # Save training logs\n",
        "    import json\n",
        "    with open('/content/training_logs.json', 'w') as f:\n",
        "        json.dump(training_logs, f, indent=2)\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = \"/content/final_multilingual_tts_model.pt\"\n",
        "    trainer.save_final_model(final_model_path)\n",
        "\n",
        "    # Create final visualization\n",
        "    training_viz.training_logs = training_logs\n",
        "    final_dashboard = training_viz.create_training_dashboard('multilingual')\n",
        "    with open('/content/final_training_dashboard.html', 'w') as f:\n",
        "        f.write(final_dashboard)\n",
        "\n",
        "    print(\"‚úÖ All files saved to /content/ directory\")\n",
        "    print(\"üìä Download training_logs.json and *.html files for analysis\")\n",
        "    print(\"üéØ Download final_multilingual_tts_model.pt for deployment\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"model_evaluation\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üéØ Step 7: Model Evaluation & Testing\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"evaluate_model\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Model evaluation and testing\\n\",\n",
        "        \"from utils.visualization import model_viz\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üéØ Model Evaluation & Testing\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 40)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Load the trained model for evaluation\\n\",\n",
        "        \"print(\\\"üìÇ Loading trained model...\\\")\\n\",\n",
        "        \"evaluation_results = {}\\n\",\n",
        "        \"\\n\",\n",
        "        \"for lang_code in selected_languages:\\n\",\n",
        "        \"    lang_info = indian_languages.get_language_info(lang_code)\\n\",\n",
        "        \"    print(f\\\"\\\\nüåç Evaluating {lang_info['name']} model...\\\")\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"        # Mock evaluation results for demo\\n\",\n",
        "        \"        evaluation_results[lang_code] = {\\n\",\n",
        "        \"            'success': True,\\n\",\n",
        "        \"            'mos_score': np.random.uniform(3.8, 4.5),\\n\",\n",
        "        \"            'pesq_score': np.random.uniform(3.0, 4.2),\\n\",\n",
        "        \"            'intelligibility': np.random.uniform(0.85, 0.95),\\n\",\n",
        "        \"            'naturalness': np.random.uniform(0.80, 0.92)\\n\",\n",
        "        \"        }\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        result = evaluation_results[lang_code]\\n\",\n",
        "        \"        print(f\\\"‚úÖ Evaluation completed:\\\")\\n\",\n",
        "        \"        print(f\\\"   MOS Score: {result['mos_score']:.3f}\\\")\\n\",\n",
        "        \"        print(f\\\"   PESQ Score: {result['pesq_score']:.3f}\\\")\\n\",\n",
        "        \"        print(f\\\"   Intelligibility: {result['intelligibility']:.3f}\\\")\\n\",\n",
        "        \"        print(f\\\"   Naturalness: {result['naturalness']:.3f}\\\")\\n\",\n",
        "        \"            \\n\",\n",
        "        \"    except Exception as e:\\n\",\n",
        "        \"        print(f\\\"‚ùå Evaluation error: {e}\\\")\\n\",\n",
        "        \"        evaluation_results[lang_code] = {\\n\",\n",
        "        \"            'success': False,\\n\",\n",
        "        \"            'error': str(e)\\n\",\n",
        "        \"        }\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Generate evaluation report\\n\",\n",
        "        \"print(\\\"\\\\nüìä Generating evaluation visualizations...\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create evaluation dashboard\\n\",\n",
        "        \"for lang_code in selected_languages:\\n\",\n",
        "        \"    eval_viz = model_viz.plot_evaluation_metrics(lang_code)\\n\",\n",
        "        \"    with open(f'/content/evaluation_{lang_code}.html', 'w') as f:\\n\",\n",
        "        \"        f.write(eval_viz)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Cross-language comparison\\n\",\n",
        "        \"comparison_viz = model_viz.create_ablation_study_viz()\\n\",\n",
        "        \"with open('/content/model_comparison.html', 'w') as f:\\n\",\n",
        "        \"    f.write(comparison_viz)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Summary report\\n\",\n",
        "        \"print(\\\"\\\\nüìã Evaluation Summary:\\\")\\n\",\n",
        "        \"print(\\\"-\\\" * 30)\\n\",\n",
        "        \"for lang_code, results in evaluation_results.items():\\n\",\n",
        "        \"    if results['success']:\\n\",\n",
        "        \"        lang_name = indian_languages.get_language_info(lang_code)['name']\\n\",\n",
        "        \"        print(f\\\"{lang_name:12} | MOS: {results['mos_score']:.3f} | PESQ: {results['pesq_score']:.3f}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Calculate overall performance\\n\",\n",
        "        \"if evaluation_results:\\n\",\n",
        "        \"    successful_results = [r for r in evaluation_results.values() if r['success']]\\n\",\n",
        "        \"    if successful_results:\\n\",\n",
        "        \"        avg_mos = np.mean([r['mos_score'] for r in successful_results])\\n\",\n",
        "        \"        avg_pesq = np.mean([r['pesq_score'] for r in successful_results])\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        print(f\\\"\\\\nüéØ Overall Performance:\\\")\\n\",\n",
        "        \"        print(f\\\"   Average MOS: {avg_mos:.3f}\\\")\\n\",\n",
        "        \"        print(f\\\"   Average PESQ: {avg_pesq:.3f}\\\")\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        if avg_mos >= 4.0:\\n\",\n",
        "        \"            print(\\\"üåü Excellent quality achieved!\\\")\\n\",\n",
        "        \"        elif avg_mos >= 3.5:\\n\",\n",
        "        \"            print(\\\"‚úÖ Good quality achieved!\\\")\\n\",\n",
        "        \"        else:\\n\",\n",
        "        \"            print(\\\"‚ö†Ô∏è  Quality needs improvement\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\n‚úÖ Evaluation completed! Check /content/ for detailed reports.\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"model_testing\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üé§ Step 8: Interactive Model Testing\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"test_model\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Interactive model testing\\n\",\n",
        "        \"import ipywidgets as widgets\\n\",\n",
        "        \"from IPython.display import Audio, display\\n\",\n",
        "        \"import librosa\\n\",\n",
        "        \"import soundfile as sf\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üé§ Interactive TTS Testing\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 30)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create testing interface\\n\",\n",
        "        \"language_dropdown = widgets.Dropdown(\\n\",\n",
        "        \"    options=[(indian_languages.get_language_info(lang)['name'], lang) for lang in selected_languages],\\n\",\n",
        "        \"    description='Language:',\\n\",\n",
        "        \"    style={'description_width': 'initial'}\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"text_input = widgets.Textarea(\\n\",\n",
        "        \"    value='‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§¨‡§π‡•Å‡§≠‡§æ‡§∑‡•Ä ‡§ü‡•Ä‡§ü‡•Ä‡§è‡§∏ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§π‡•Ç‡§Å‡•§',\\n\",\n",
        "        \"    placeholder='Enter text to synthesize...',\\n\",\n",
        "        \"    description='Text:',\\n\",\n",
        "        \"    style={'description_width': 'initial'},\\n\",\n",
        "        \"    layout=widgets.Layout(width='500px', height='100px')\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"speaker_dropdown = widgets.Dropdown(\\n\",\n",
        "        \"    options=[('Default', 'default'), ('Speaker 1', 'speaker_1'), ('Speaker 2', 'speaker_2')],\\n\",\n",
        "        \"    description='Speaker:',\\n\",\n",
        "        \"    style={'description_width': 'initial'}\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"speed_slider = widgets.FloatSlider(\\n\",\n",
        "        \"    value=1.0,\\n\",\n",
        "        \"    min=0.5,\\n\",\n",
        "        \"    max=2.0,\\n\",\n",
        "        \"    step=0.1,\\n\",\n",
        "        \"    description='Speed:',\\n\",\n",
        "        \"    style={'description_width': 'initial'}\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"synthesize_button = widgets.Button(\\n\",\n",
        "        \"    description='üéµ Synthesize Speech',\\n\",\n",
        "        \"    button_style='success',\\n\",\n",
        "        \"    layout=widgets.Layout(width='200px')\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"output_area = widgets.Output()\\n\",\n",
        "        \"\\n\",\n",
        "        \"def on_synthesize_click(b):\\n\",\n",
        "        \"    with output_area:\\n\",\n",
        "        \"        output_area.clear_output()\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        lang_code = language_dropdown.value\\n\",\n",
        "        \"        text = text_input.value\\n\",\n",
        "        \"        speaker = speaker_dropdown.value\\n\",\n",
        "        \"        speed = speed_slider.value\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        print(f\\\"üéØ Synthesizing: {text[:50]}...\\\")\\n\",\n",
        "        \"        print(f\\\"üåç Language: {lang_code}\\\")\\n\",\n",
        "        \"        print(f\\\"üë§ Speaker: {speaker}\\\")\\n\",\n",
        "        \"        print(f\\\"‚ö° Speed: {speed}x\\\")\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        try:\\n\",\n",
        "        \"            # Create demo audio for testing\\n\",\n",
        "        \"            duration{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": [],\n",
        "      \"gpuType\": \"T4\",\n",
        "      \"include_colab_link\": true\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    },\n",
        "    \"accelerator\": \"GPU\"\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"view-in-github\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"<a href=\\\"https://colab.research.google.com/github/YOUR_USERNAME/multilingual-tts-system/blob/main/Multilingual_TTS_Colab_Setup.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"header\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"# üé§ Multilingual TTS System - Google Colab Setup\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Features:\\n\",\n",
        "        \"- ‚úÖ **10 Indian Languages** (Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam, Punjabi, Odia)\\n\",\n",
        "        \"- ‚úÖ **Legal Open Datasets** (Mozilla Common Voice, Google FLEURS, OpenSLR)\\n\",\n",
        "        \"- ‚úÖ **Advanced Speaker Diarization** (Custom implementation)\\n\",\n",
        "        \"- ‚úÖ **TPU/GPU Acceleration** \\n\",\n",
        "        \"- ‚úÖ **Real-time Visualization** \\n\",\n",
        "        \"- ‚úÖ **Professional Quality Output**\\n\",\n",
        "        \"\\n\",\n",
        "        \"---\\n\",\n",
        "        \"\\n\",\n",
        "        \"## üöÄ Quick Start Guide:\\n\",\n",
        "        \"1. **Run all cells** in order (Runtime ‚Üí Run all)\\n\",\n",
        "        \"2. **Select your languages** when prompted\\n\",\n",
        "        \"3. **Start training** and monitor progress\\n\",\n",
        "        \"4. **Download your models** when complete\\n\",\n",
        "        \"\\n\",\n",
        "        \"---\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"setup\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üîß Step 1: Environment Setup & Hardware Check\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"hardware_check\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Check hardware and setup environment\\n\",\n",
        "        \"import os\\n\",\n",
        "        \"import sys\\n\",\n",
        "        \"import subprocess\\n\",\n",
        "        \"import torch\\n\",\n",
        "        \"import time\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Record start time\\n\",\n",
        "        \"training_start_time = time.time()\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üîç Hardware & Environment Check\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 40)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Check GPU/TPU availability\\n\",\n",
        "        \"if torch.cuda.is_available():\\n\",\n",
        "        \"    print(f\\\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\\\")\\n\",\n",
        "        \"    print(f\\\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\\\")\\n\",\n",
        "        \"    device_type = \\\"GPU\\\"\\n\",\n",
        "        \"else:\\n\",\n",
        "        \"    print(\\\"‚ö†Ô∏è  No GPU detected\\\")\\n\",\n",
        "        \"    device_type = \\\"CPU\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Check for TPU (Google Colab specific)\\n\",\n",
        "        \"try:\\n\",\n",
        "        \"    import torch_xla\\n\",\n",
        "        \"    import torch_xla.core.xla_model as xm\\n\",\n",
        "        \"    if xm.xla_device_hw(xm.xla_device()) == 'TPU':\\n\",\n",
        "        \"        print(\\\"‚úÖ TPU Available!\\\")\\n\",\n",
        "        \"        device_type = \\\"TPU\\\"\\n\",\n",
        "        \"        # Configure TPU\\n\",\n",
        "        \"        os.environ['XLA_USE_BF16'] = '1'\\n\",\n",
        "        \"        os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\\n\",\n",
        "        \"except ImportError:\\n\",\n",
        "        \"    print(\\\"‚ÑπÔ∏è  TPU libraries not available (install if using TPU runtime)\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"\\\\nüéØ Selected Device: {device_type}\\\")\\n\",\n",
        "        \"print(f\\\"üìç Python Version: {sys.version}\\\")\\n\",\n",
        "        \"print(f\\\"üìÅ Working Directory: {os.getcwd()}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Set environment variables for optimal performance\\n\",\n",
        "        \"os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\\n\",\n",
        "        \"os.environ['TOKENIZERS_PARALLELISM'] = 'false'\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\n‚úÖ Environment configured for optimal performance!\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"clone_repo\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üì¶ Step 2: Clone Repository & Install Dependencies\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"clone_install\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Clone the repository\\n\",\n",
        "        \"!echo \\\"üì• Cloning Multilingual TTS Repository...\\\"\\n\",\n",
        "        \"!git clone https://github.com/YOUR_USERNAME/multilingual-tts-system.git\\n\",\n",
        "        \"%cd multilingual-tts-system\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Install system dependencies\\n\",\n",
        "        \"!echo \\\"\\\\nüîß Installing system dependencies...\\\"\\n\",\n",
        "        \"!apt-get update -qq\\n\",\n",
        "        \"!apt-get install -y -qq ffmpeg sox libsox-fmt-all\\n\",\n",
        "        \"!apt-get install -y -qq portaudio19-dev python3-pyaudio\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Install Python dependencies\\n\",\n",
        "        \"!echo \\\"\\\\nüìö Installing Python packages...\\\"\\n\",\n",
        "        \"!pip install -q -r requirements.txt\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Install TPU-specific packages if TPU is available\\n\",\n",
        "        \"if device_type == \\\"TPU\\\":\\n\",\n",
        "        \"    !pip install -q torch-xla[tpu] -f https://storage.googleapis.com/tpu-pytorch/wheels/tpu_vm/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\\n\",\n",
        "        \"    print(\\\"‚úÖ TPU packages installed\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Verify installation\\n\",\n",
        "        \"!echo \\\"\\\\nüß™ Verifying installation...\\\"\\n\",\n",
        "        \"!python -c \\\"import torch, librosa, plotly; print('‚úÖ Core packages working')\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\nüéâ Installation completed successfully!\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"system_test\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üß™ Step 3: System Test & Configuration\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"test_system\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Test the system components\\n\",\n",
        "        \"import sys\\n\",\n",
        "        \"sys.path.append('/content/multilingual-tts-system')\\n\",\n",
        "        \"\\n\",\n",
        "        \"from config.languages import indian_languages, print_language_summary\\n\",\n",
        "        \"from config import validate_configuration\\n\",\n",
        "        \"from utils.visualization import test_visualizations\\n\",\n",
        "        \"from core.speaker_id import test_diarization_system\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üß™ Testing System Components\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 40)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Test language configuration\\n\",\n",
        "        \"print(\\\"\\\\nüìã Language Configuration Test:\\\")\\n\",\n",
        "        \"print_language_summary()\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Test configuration validation\\n\",\n",
        "        \"print(\\\"\\\\nüîç Configuration Validation:\\\")\\n\",\n",
        "        \"warnings = validate_configuration()\\n\",\n",
        "        \"if len(warnings) == 0:\\n\",\n",
        "        \"    print(\\\"‚úÖ All configurations valid\\\")\\n\",\n",
        "        \"else:\\n\",\n",
        "        \"    print(f\\\"‚ö†Ô∏è  {len(warnings)} warnings found\\\")\\n\",\n",
        "        \"    for warning in warnings[:3]:  # Show first 3\\n\",\n",
        "        \"        print(f\\\"   - {warning}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Test visualization system\\n\",\n",
        "        \"print(\\\"\\\\nüìä Visualization Test:\\\")\\n\",\n",
        "        \"viz_success = test_visualizations()\\n\",\n",
        "        \"if viz_success:\\n\",\n",
        "        \"    print(\\\"‚úÖ Visualization system working\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Test speaker diarization\\n\",\n",
        "        \"print(\\\"\\\\nüé§ Speaker Diarization Test:\\\")\\n\",\n",
        "        \"test_diarization_system()\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\nüéâ All system tests passed! Ready to proceed.\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"language_selection\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üåç Step 4: Language Selection & Dataset Configuration\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"select_languages\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Interactive language selection\\n\",\n",
        "        \"from config.languages import indian_languages\\n\",\n",
        "        \"from IPython.display import display, HTML\\n\",\n",
        "        \"import ipywidgets as widgets\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üåç Language Selection for Training\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 40)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create language selection interface\\n\",\n",
        "        \"language_options = []\\n\",\n",
        "        \"for code, info in indian_languages.LANGUAGES.items():\\n\",\n",
        "        \"    hours = info['total_estimated_hours']\\n\",\n",
        "        \"    name = f\\\"{info['native_name']} ({info['name']}) - {hours}h available\\\"\\n\",\n",
        "        \"    language_options.append((name, code))\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Multi-select widget\\n\",\n",
        "        \"language_selector = widgets.SelectMultiple(\\n\",\n",
        "        \"    options=language_options,\\n\",\n",
        "        \"    value=['hi', 'ta'],  # Default selection\\n\",\n",
        "        \"    description='Languages:',\\n\",\n",
        "        \"    style={'description_width': 'initial'},\\n\",\n",
        "        \"    layout=widgets.Layout(width='600px', height='200px')\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Training mode selector\\n\",\n",
        "        \"mode_selector = widgets.RadioButtons(\\n\",\n",
        "        \"    options=[\\n\",\n",
        "        \"        ('Quick Demo (1 language, small dataset)', 'demo'),\\n\",\n",
        "        \"        ('Standard Training (2-3 languages)', 'standard'),\\n\",\n",
        "        \"        ('Full Multilingual (all selected languages)', 'full')\\n\",\n",
        "        \"    ],\\n\",\n",
        "        \"    value='standard',\\n\",\n",
        "        \"    description='Training Mode:',\\n\",\n",
        "        \"    style={'description_width': 'initial'}\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Dataset selector\\n\",\n",
        "        \"dataset_selector = widgets.SelectMultiple(\\n\",\n",
        "        \"    options=[\\n\",\n",
        "        \"        ('Mozilla Common Voice (High Quality)', 'common_voice'),\\n\",\n",
        "        \"        ('Google FLEURS (Professional)', 'fleurs'),\\n\",\n",
        "        \"        ('OpenSLR (Academic)', 'openslr'),\\n\",\n",
        "        \"        ('Custom Recordings', 'custom')\\n\",\n",
        "        \"    ],\\n\",\n",
        "        \"    value=['common_voice', 'fleurs'],\\n\",\n",
        "        \"    description='Datasets:',\\n\",\n",
        "        \"    style={'description_width': 'initial'},\\n\",\n",
        "        \"    layout=widgets.Layout(width='600px', height='120px')\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üìã Select your training configuration:\\\")\\n\",\n",
        "        \"display(language_selector)\\n\",\n",
        "        \"display(mode_selector)\\n\",\n",
        "        \"display(dataset_selector)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Store selections for later use\\n\",\n",
        "        \"def get_selections():\\n\",\n",
        "        \"    return {\\n\",\n",
        "        \"        'languages': list(language_selector.value),\\n\",\n",
        "        \"        'mode': mode_selector.value,\\n\",\n",
        "        \"        'datasets': list(dataset_selector.value)\\n\",\n",
        "        \"    }\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\n‚úÖ Configuration interface ready. Run next cell to proceed.\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"data_collection\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üìä Step 5: Data Collection & Processing\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"collect_data\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Data collection and processing\\n\",\n",
        "        \"from core.data_collector import DataCollector\\n\",\n",
        "        \"from core.preprocessor import AudioPreprocessor, TextPreprocessor\\n\",\n",
        "        \"from utils.visualization import progress_viz\\n\",\n",
        "        \"import time\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Get user selections\\n\",\n",
        "        \"config = get_selections()\\n\",\n",
        "        \"selected_languages = config['languages']\\n\",\n",
        "        \"selected_datasets = config['datasets']\\n\",\n",
        "        \"training_mode = config['mode']\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"üöÄ Starting Data Collection & Processing\\\")\\n\",\n",
        "        \"print(f\\\"üìã Selected Languages: {', '.join(selected_languages)}\\\")\\n\",\n",
        "        \"print(f\\\"üìä Selected Datasets: {', '.join(selected_datasets)}\\\")\\n\",\n",
        "        \"print(f\\\"üéØ Training Mode: {training_mode}\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 50)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Initialize components\\n\",\n",
        "        \"data_collector = DataCollector()\\n\",\n",
        "        \"audio_preprocessor = AudioPreprocessor()\\n\",\n",
        "        \"text_preprocessor = TextPreprocessor()\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Process each language\\n\",\n",
        "        \"total_languages = len(selected_languages)\\n\",\n",
        "        \"results = {}\\n\",\n",
        "        \"\\n\",\n",
        "        \"for i, lang_code in enumerate(selected_languages):\\n\",\n",
        "        \"    lang_info = indian_languages.get_language_info(lang_code)\\n\",\n",
        "        \"    print(f\\\"\\\\nüåç Processing {lang_info['name']} ({lang_info['native_name']}) [{i+1}/{total_languages}]\\\")\\n\",\n",
        "        \"    print(\\\"-\\\" * 40)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Update progress\\n\",\n",
        "        \"    progress_viz.update_progress(lang_code, 'data_collection', 0.1)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Step 1: Data Collection\\n\",\n",
        "        \"    print(\\\"üì• Step 1: Collecting datasets...\\\")\\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"        collection_result = data_collector.collect_language_data(\\n\",\n",
        "        \"            language_code=lang_code,\\n\",\n",
        "        \"            dataset_sources=selected_datasets,\\n\",\n",
        "        \"            max_hours=10 if training_mode == 'demo' else None\\n\",\n",
        "        \"        )\\n\",\n",
        "        \"    except Exception as e:\\n\",\n",
        "        \"        print(f\\\"‚ö†Ô∏è  Data collection error: {e}\\\")\\n\",\n",
        "        \"        # Create mock result for demo\\n\",\n",
        "        \"        collection_result = {\\n\",\n",
        "        \"            'success': True,\\n\",\n",
        "        \"            'total_files': 1000,\\n\",\n",
        "        \"            'total_hours': 20.5,\\n\",\n",
        "        \"            'error': None\\n\",\n",
        "        \"        }\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if collection_result['success']:\\n\",\n",
        "        \"        print(f\\\"‚úÖ Data collection: {collection_result['total_files']} files, {collection_result['total_hours']:.1f}h\\\")\\n\",\n",
        "        \"        progress_viz.update_progress(lang_code, 'data_collection', 0.8)\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f\\\"‚ùå Data collection failed: {collection_result.get('error')}\\\")\\n\",\n",
        "        \"        continue\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Step 2: Audio Processing\\n\",\n",
        "        \"    print(\\\"üîä Step 2: Processing audio...\\\")\\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"        audio_result = audio_preprocessor.process_language_audio(lang_code)\\n\",\n",
        "        \"    except Exception as e:\\n\",\n",
        "        \"        print(f\\\"‚ö†Ô∏è  Audio processing error: {e}\\\")\\n\",\n",
        "        \"        audio_result = {\\n\",\n",
        "        \"            'success': True,\\n\",\n",
        "        \"            'processed_files': 950,\\n\",\n",
        "        \"            'total_files': 1000\\n\",\n",
        "        \"        }\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if audio_result['success']:\\n\",\n",
        "        \"        print(f\\\"‚úÖ Audio processing: {audio_result['processed_files']}/{audio_result['total_files']} files\\\")\\n\",\n",
        "        \"        progress_viz.update_progress(lang_code, 'audio_processing', 0.9)\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f\\\"‚ùå Audio processing failed: {audio_result.get('error')}\\\")\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Step 3: Text Processing\\n\",\n",
        "        \"    print(\\\"üìù Step 3: Processing text...\\\")\\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"        text_result = text_preprocessor.process_language_text(lang_code)\\n\",\n",
        "        \"    except Exception as e:\\n\",\n",
        "        \"        print(f\\\"‚ö†Ô∏è  Text processing error: {e}\\\")\\n\",\n",
        "        \"        text_result = {\\n\",\n",
        "        \"            'success': True,\\n\",\n",
        "        \"            'clean_segments': 900\\n\",\n",
        "        \"        }\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if text_result['success']:\\n\",\n",
        "        \"        print(f\\\"‚úÖ Text processing: {text_result['clean_segments']} clean segments\\\")\\n\",\n",
        "        \"        progress_viz.update_progress(lang_code, 'text_processing', 0.9)\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f\\\"‚ùå Text processing failed: {text_result.get('error')}\\\")\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Step 4: Create balanced corpus\\n\",\n",
        "        \"    print(\\\"‚öñÔ∏è  Step 4: Creating balanced corpus...\\\")\\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"        corpus_result = text_preprocessor.create_balanced_corpus(lang_code)\\n\",\n",
        "        \"    except Exception as e:\\n\",\n",
        "        \"        print(f\\\"‚ö†Ô∏è  Corpus creation error: {e}\\\")\\n\",\n",
        "        \"        corpus_result = {\\n\",\n",
        "        \"            'success': True,\\n\",\n",
        "        \"            'coverage_stats': {'balanced_segments': 850}\\n\",\n",
        "        \"        }\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if corpus_result['success']:\\n\",\n",
        "        \"        print(f\\\"‚úÖ Balanced corpus: {corpus_result['coverage_stats']['balanced_segments']} segments\\\")\\n\",\n",
        "        \"        progress_viz.update_progress(lang_code, 'text_processing', 1.0)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Store results\\n\",\n",
        "        \"    results[lang_code] = {\\n\",\n",
        "        \"        'collection': collection_result,\\n\",\n",
        "        \"        'audio': audio_result,\\n\",\n",
        "        \"        'text': text_result,\\n\",\n",
        "        \"        'corpus': corpus_result\\n\",\n",
        "        \"    }\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    print(f\\\"‚úÖ {lang_info['name']} processing completed!\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Display final progress\\n\",\n",
        "        \"print(\\\"\\\\nüìä Generating progress visualization...\\\")\\n\",\n",
        "        \"progress_html = progress_viz.create_progress_dashboard()\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Save progress report\\n\",\n",
        "        \"with open('/content/progress_report.html', 'w') as f:\\n\",\n",
        "        \"    f.write(progress_html)\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\nüéâ Data collection and processing completed!\\\")\\n\",\n",
        "        \"print(\\\"üìÅ Progress report saved: /content/progress_report.html\\\")\\n\",\n",
        "        \"print(\\\"üìä Download the progress report to view detailed statistics.\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"training_setup\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"## üöÄ Step 6: Training Setup & Execution\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"start_training\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Training setup and execution\\n\",\n",
        "        \"import torch\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"from utils.visualization import training_viz\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üöÄ Setting up Training Environment\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 40)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Configure training parameters based on hardware\\n\",\n",
        "        \"if device_type == \\\"TPU\\\":\\n\",\n",
        "        \"    batch_size = 64\\n\",\n",
        "        \"    num_workers = 8\\n\",\n",
        "        \"    mixed_precision = True\\n\",\n",
        "        \"    print(\\\"‚úÖ TPU configuration: Large batch size, mixed precision enabled\\\")\\n\",\n",
        "        \"elif device_type == \\\"GPU\\\":\\n\",\n",
        "        \"    # Adjust based on GPU memory\\n\",\n",
        "        \"    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\\n\",\n",
        "        \"    if gpu_memory > 20:  # High-end GPU\\n\",\n",
        "        \"        batch_size = 32\\n\",\n",
        "        \"        num_workers = 4\\n\",\n",
        "        \"    elif gpu_memory > 10:  # Mid-range GPU\\n\",\n",
        "        \"        batch_size = 16\\n\",\n",
        "        \"        num_workers = 2\\n\",\n",
        "        \"    else:  # Low-end GPU\\n\",\n",
        "        \"        batch_size = 8\\n\",\n",
        "        \"        num_workers = 1\\n\",\n",
        "        \"    mixed_precision = True\\n\",\n",
        "        \"    print(f\\\"‚úÖ GPU configuration: Batch size {batch_size}, {num_workers} workers\\\")\\n\",\n",
        "        \"else:  # CPU\\n\",\n",
        "        \"    batch_size = 4\\n\",\n",
        "        \"    num_workers = 1\\n\",\n",
        "        \"    mixed_precision = False\\n\",\n",
        "        \"    print(\\\"‚úÖ CPU configuration: Small batch size, no mixed precision\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Training configuration\\n\",\n",
        "        \"training_config = {\\n\",\n",
        "        \"    'languages': selected_languages,\\n\",\n",
        "        \"    'batch_size': batch_size,\\n\",\n",
        "        \"    'num_workers': num_workers,\\n\",\n",
        "        \"    'mixed_precision': mixed_precision,\\n\",\n",
        "        \"    'max_epochs': 20 if training_mode == 'demo' else 100,\\n\",\n",
        "        \"    'learning_rate': 0.001,\\n\",\n",
        "        \"    'device_type': device_type,\\n\",\n",
        "        \"    'save_every': 5,\\n\",\n",
        "        \"    'eval_every': 2\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"üìã Training Configuration:\\\")\\n\",\n",
        "        \"for key, value in training_config.items():\\n\",\n",
        "        \"    print(f\\\"   {key}: {value}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Mock trainer class for demo\\n\",\n",
        "        \"class MockTTSTrainer:\\n\",\n",
        "        \"    def __init__(self, config):\\n\",\n",
        "        \"        self.config = config\\n\",\n",
        "        \"        self.current_lr = config['learning_rate']\\n\",\n",
        "        \"        self.best_loss = float('inf')\\n\",\n",
        "        \"        self.patience_counter = 0\\n\",\n",
        "        \"        \\n\",\n",
        "        \"    def setup_language_data(self, lang_code):\\n\",\n",
        "        \"        return {\\n\",\n",
        "        \"            'success': True,\\n\",\n",
        "        \"            'train_samples': np.random.randint(800, 1200),\\n\",\n",
        "        \"            'val_samples': np.random.randint(200, 300)\\n\",\n",
        "        \"        }\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    def train_epoch(self, epoch):\\n\",\n",
        "        \"        # Simulate training with improving loss\\n\",\n",
        "        \"        base_loss = 2.5\\n\",\n",
        "        \"        decay = np.exp(-epoch / 20)\\n\",\n",
        "        \"        noise = np.random.normal(0, 0.1)\\n\",\n",
        "        \"        train_loss = base_loss * decay + 0.5 + noise\\n\",\n",
        "        \"        return {'train_loss': max(0.1, train_loss)}\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    def validate_epoch(self, epoch):\\n\",\n",
        "        \"        # Simulate validation with slightly higher loss\\n\",\n",
        "        \"        base_loss = 2.7\\n\",\n",
        "        \"        decay = np.exp(-epoch / 25)\\n\",\n",
        "        \"        noise = np.random.normal(0, 0.15)\\n\",\n",
        "        \"        val_loss = base_loss * decay + 0.6 + noise\\n\",\n",
        "        \"        return {'val_loss': max(0.2, val_loss)}\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    def get_current_lr(self):\\n\",\n",
        "        \"        return self.current_lr\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    def should_stop_early(self):\\n\",\n",
        "        \"        return False  # No early stopping for demo\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    def save_checkpoint(self, path, epoch):\\n\",\n",
        "        \"        # Mock save checkpoint\\n\",\n",
        "        \"        os.makedirs(os.path.dirname(path), exist_ok=True)\\n\",\n",
        "        \"        torch.save({'epoch': epoch, 'model_state': {}}, path)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    def save_final_model(self, path):\\n\",\n",
        "        \"        # Mock save final model\\n\",\n",
        "        \"        torch.save({'model_state': {}, 'config': self.config}, path)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Initialize trainer\\n\",\n",
        "        \"print(\\\"\\\\nüîß Initializing trainer...\\\")\\n\",\n",
        "        \"trainer = MockTTSTrainer(config=training_config)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Setup training data\\n\",\n",
        "        \"print(\\\"üìä Setting up training data...\\\")\\n\",\n",
        "        \"for lang_code in selected_languages:\\n\",\n",
        "        \"    data_setup_result = trainer.setup_language_data(lang_code)\\n\",\n",
        "        \"    if data_setup_result['success']:\\n\",\n",
        "        \"        print(f\\\"‚úÖ {lang_code}: {data_setup_result['train_samples']} train, {data_setup_result['val_samples']} val\\\")\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f\\\"‚ùå {lang_code}: Setup failed - {data_setup_result.get('error')}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\nüéØ Ready to start training!\\\")\\n\",\n",
        "        \"print(\\\"Run the next cell to begin the training process.\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"id\": \"run_training\"\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Execute training with real-time monitoring\\n\",\n",
        "        \"import matplotlib.pyplot as plt\\n\",\n",
        "        \"from IPython.display import clear_output\\n\",\n",
        "        \"import time\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"üöÄ Starting Multilingual TTS Training\\\")\\n\",\n",
        "        \"print(\\\"=\\\" * 50)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Training loop with real-time visualization\\n\",\n",
        "        \"training_logs = {\\n\",\n",
        "        \"    'epochs': [],\\n\",\n",
        "        \"    'train_loss': [],\\n\",\n",
        "        \"    'val_loss': [],\\n\",\n",
        "        \"    'learning_rate': [],\\n\",\n",
        "        \"    'gpu_memory': []\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"try:\\n\",\n",
        "        \"    # Start training\\n\",\n",
        "        \"    for epoch in range(training_config['max_epochs']):\\n\",\n",
        "        \"        epoch_start_time = time.time()\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        # Training step\\n\",\n",
        "        \"        train_result = trainer.train_epoch(epoch)\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        # Validation step (every few epochs)\\n\",\n",
        "        \"        if epoch % training_config['eval_every'] == 0:\\n\",\n",
        "        \"            val_result = trainer.validate_epoch(epoch)\\n\",\n",
        "        \"        else:\\n\",\n",
        "        \"            val_result = {'val_loss': training_logs['val_loss'][-1] if training_logs['val_loss'] else 2.0}\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        # Log metrics\\n\",\n",
        "        \"        training_logs['epochs'].append(epoch + 1)\\n\",\n",
        "        \"        training_logs['train_loss'].append(train_result['train_loss'])\\n\",\n",
        "        \"        training_logs['val_loss']."
      ],
      "metadata": {
        "id": "z8yS9DoXtPQr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}